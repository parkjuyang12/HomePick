# 전체 아키텍처 개요 (개념 정리본)

> **이 서비스는 “주기적으로 변하는 공공데이터를 이벤트로 수집하고,
> Flink에서 ‘판단과 상태 관리’를 맡고,
> Elasticsearch에서는 ‘조회 최적화된 결과’만 제공하는 구조”.**

---

## 1️⃣ 전체 데이터 흐름 (큰 그림)

```
[공공데이터 포털 API]
        │
        │ (10분 주기 Polling)
        ▼
[API Poller]
        │
        │  원천 데이터 (중복/변경 포함)
        ▼
Kafka
(raw.<api_name>)
        │
        │  스트림 처리
        ▼
Apache Flink
(중복 제거 · 최신 판단 · 히스토리 생성)
        │
        ├───────────────▶ Elasticsearch (current)
        │                   - 최신 상태 조회용
        │
        └───────────────▶ Elasticsearch (history)
                            - 거래/변경 이력
```

---

## 2️⃣ 각 컴포넌트의 **역할을 명확히 분리**

### 🔹 ① API Poller (수집기)

**책임**

* 공공데이터 API를 **10분마다 호출**
* 가능한 경우:

  * `lastUpdated`
  * `page`
  * `from~to`
    같은 **증분 조건**을 최대한 사용

**중요한 점**

* ❌ 여기서 중복 판단 안 함
* ❌ 여기서 비즈니스 로직 안 넣음
* ⭕ “사실 그대로” Kafka에 적재

> Poller는 **수집기**, 판단자는 아님

### api 조회시점 Checkpoint Store
```
collector_state
-----------------------
key            | value
-----------------------
last_fetch_at  | 2025-01-02T10:00:00
```
> 조회 시점은 postgres db에 계속 업데이트(체크포인트) 하여, 컨테이너 중지 후 다시 api를 호출하더라도 이 시점을 기준으로 하여 현재까지의 api 호출 후 정상 주기 호출 로직으로 회귀

---

### 🔹 ② Kafka (이벤트 로그, 단일 진실 원천)

Kafka는 **캐시도, DB도 아님**

**역할**

* 공공 API 응답을 **시간 순서대로 보존**
* 재처리, 장애 복구, 리플레이 가능

**토픽 개념**

```
raw.real_estate
raw.transaction
raw.notice
```

👉 여기에는

* 중복 있음
* 수정 전/후 섞여 있음
* “있는 그대로의 세상”

---

## 3️⃣ 이 아키텍처의 핵심: **Apache Flink**

> **Flink = 이 시스템의 두뇌 + 상태 관리자**

### Flink가 담당하는 핵심 책임

### ✅ 1. “이게 새로운 데이터인가?”

* PK 기준 (매물ID / 거래ID 등)
* Keyed State에 **마지막 상태 저장**
* 동일 → 무시
* 변경 → 처리

👉 Redis 캐싱 역할을 **State**로 대체

---

### ✅ 2. “최신 상태는 무엇인가?”

* 가격
* 상태 (거래중 / 거래완료)
* 마지막 갱신 시점

👉 Flink 내부에 **항상 최신 상태가 존재**

---

### ✅ 3. “히스토리를 만들어낸다”

공공데이터 API는 보통:

* 과거 이력을 안 줌
* 최신 스냅샷만 줌

그래서 Flink가:

* **이전 상태와 현재 상태를 비교**
* “변경 이벤트”를 생성

예:

* PRICE_CHANGE
* SOLD
* STATUS_CHANGE

👉 히스토리는 **저장하는 게 아니라 생성하는 것**

---

## 4️⃣ Elasticsearch를 두 개로 나누는 이유 (매우 중요)

### 🔹 Index 1: `*_current` (최신 상태 전용)

**목적**

* 서비스 조회
* 빠른 검색 / 필터 / 정렬

**특징**

* 매물 1개 = 문서 1개
* document_id = 매물ID
* Flink에서 **upsert**

예:

```json
{
  "listing_id": "A123",
  "price": 850000000,
  "status": "SOLD",
  "region": "서울",
  "updated_at": "2025-12-15T10:00:00"
}
```

👉 “지금 이 매물은 어떤 상태인가?”

---

### 🔹 Index 2: `*_history` (거래/변경 이력)

**목적**

* 히스토리 조회
* 타임라인 / 분석

**특징**

* append-only
* 변경 발생 시에만 insert
* 삭제 거의 없음

예:

```json
{
  "listing_id": "A123",
  "event_time": "2025-12-15T10:00:00",
  "event_type": "PRICE_CHANGE",
  "old_price": 900000000,
  "new_price": 850000000
}
```

👉 “이 매물은 언제 어떻게 바뀌었나?”

---

## 5️⃣ 왜 Redis를 쓰지 않아도 되나?

### Redis가 하던 일

* 중복 방지
* 최신 상태 캐싱

### 이 아키텍처에서는

* 중복/최신 판단 → **Flink State**
* 조회 성능 → **Elasticsearch**

즉,

> Redis의 역할이 **분해되어 더 적합한 컴포넌트로 이동**

---

## 6️⃣ 서비스 조회 시나리오 정리

### 📌 매물 목록 조회

* Elasticsearch `*_current`
* 조건 검색, 정렬, 페이지네이션

### 📌 특정 매물 상세

* current → 현재 상태
* history → 거래/가격 변동 타임라인

### 📌 분석/통계

* history index 기반
* 기간별, 지역별 변화 분석

---

## 7️⃣ 이 아키텍처의 핵심 철학 (진짜 중요한 부분)

1. **Kafka에는 “사실”만 남긴다**
2. **판단과 상태 관리는 Flink가 한다**
3. **Elasticsearch는 “결과 조회”만 담당한다**
4. **히스토리는 스냅샷이 아니라 “변경 이벤트”다**

---

## 8️⃣ 한 문장 요약

> **주기적으로 수집되는 공공데이터를 Kafka에 이벤트로 저장하고,
> Flink에서 중복 제거·상태 판단·히스토리 생성을 수행한 뒤,
> Elasticsearch에는 최신 상태와 변경 이력을 분리 저장하는 아키텍처다.**


