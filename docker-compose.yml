version: "3.8"

services:
  # ------------------------
  # DB
  # ------------------------
  db:
    image: postgres:14-alpine
    container_name: postgres_db
    environment:
      POSTGRES_DB: ${DB_NAME}
      POSTGRES_USER: ${DB_USER}
      POSTGRES_PASSWORD: ${DB_PASSWORD}
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
    restart: unless-stopped

  # ------------------------
  # Backend
  # ------------------------
  web:
    build:
      context: ./backend
    container_name: django_web
    ports:
      - "8000:8000"
    volumes:
      - ./backend:/app
    environment:
      DJANGO_DB_NAME: ${DB_NAME}
      DJANGO_DB_USER: ${DB_USER}
      DJANGO_DB_PASSWORD: ${DB_PASSWORD}
      DJANGO_DB_HOST: db
      DJANGO_DB_PORT: 5432
      GMS_API_KEY: ${GMS_API_KEY}
    depends_on:
      - db

  # ------------------------
  # Frontend
  # ------------------------
  frontend:
    build:
      context: ./frontend
    container_name: vue_frontend
    command: npm run serve
    ports:
      - "8080:8080"
    volumes:
      - ./frontend:/app
      - /app/node_modules
    depends_on:
      - web

  # ------------------------
  # Kafka
  # ------------------------
  zookeeper:
    image: zookeeper:3.9
    container_name: zookeeper
    ports:
      - "2181:2181"
    volumes:
      - zk-data:/data
      - zk-datalog:/datalog

  kafka:
    image: confluentinc/cp-kafka:7.6.1
    container_name: kafka
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      # docker-compose.yml의 일부
      # KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      # KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092
      # KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:29092,PLAINTEXT_HOST://0.0.0.0:9092
      # KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
    volumes:
      - kafka_data:/var/lib/kafka/data
    depends_on:
      - zookeeper

  kafka-producer:
    build:
      context: ./transaction-kafka-producer
    container_name: kafka_producer
    depends_on:
      - kafka
    env_file:
      - ./transaction-kafka-producer/.env
    restart: unless-stopped

  # ------------------------
  # Flink Session Cluster
  # ------------------------
  flink-jobmanager:
    build:
      context: ./flink
    container_name: flink_jobmanager
    command: jobmanager
    ports:
      - "8081:8081"
    environment:
      - |
        FLINK_PROPERTIES=
        jobmanager.rpc.address: flink-jobmanager
        jobmanager.memory.process.size: 1024m
        parallelism.default: 2
      - PYTHONPATH=/opt/homepick/flink:/opt/flink/job
    volumes:
      - ./flink/job:/opt/flink/job
      - ./flink:/opt/homepick/flink
      - flink_checkpoints:/opt/flink/checkpoints
      - flink_savepoints:/opt/flink/savepoints

  flink-taskmanager:
    build:
      context: ./flink
    container_name: flink_taskmanager
    command: taskmanager
    depends_on:
      - flink-jobmanager
    environment:
      - |
        FLINK_PROPERTIES=
        jobmanager.rpc.address: flink-jobmanager
        taskmanager.memory.process.size: 1024m
        taskmanager.numberOfTaskSlots: 2
      - PYTHONPATH=/opt/homepick/flink:/opt/flink/job
    volumes:
      - ./flink:/opt/homepick/flink
      - flink_checkpoints:/opt/flink/checkpoints
      - flink_savepoints:/opt/flink/savepoints

  # ------------------------
  # Flink Job
  # ------------------------
  # flink-job:
  #   build:
  #     context: ./flink
  #   container_name: flink_job
  #   depends_on:
  #     - flink-jobmanager
  #   restart: "no"

  # ------------------------
  # Elasticsearch
  # ------------------------
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:7.17.13
    container_name: elasticsearch
    environment:
      discovery.type: single-node
      xpack.security.enabled: "false"
    ports:
      - "9200:9200"
    volumes:
      - es_data:/usr/share/elasticsearch/data

  # ------------------------
  # Kibana
  # ------------------------
  kibana:
    image: docker.elastic.co/kibana/kibana:7.17.13
    container_name: kibana
    ports:
      - "5601:5601"
    environment:
      ELASTICSEARCH_HOSTS: http://elasticsearch:9200
    depends_on:
      - elasticsearch

  # ------------------------
  # Geo-Enricher
  # ------------------------
  geo-enricher:
    build:
      context: ./geo-enricher
    container_name: geo_enricher
    env_file:
      - .env
    restart: unless-stopped

# ------------------------
# Volumes
# ------------------------
volumes:
  postgres_data:
  zk-data:
  zk-datalog:
  kafka_data:
  flink_checkpoints:
  flink_savepoints:
  es_data:
